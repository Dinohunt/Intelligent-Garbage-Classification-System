{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Smart system based on Deep Convolutional Neural Networks to classify Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    " \n",
    "\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#model selection\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#preprocess.\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "#dl libraraies\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.applications import VGG16\n",
    "from keras import models\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for reproducibility\n",
    "np.random.seed(78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "X=[]\n",
    "Z=[]\n",
    "def load_data(document,DIR):\n",
    "        for img in tqdm(os.listdir(DIR)):\n",
    "            label = document\n",
    "            path = os.path.join(DIR,img)\n",
    "            image= load_img(path,target_size=(IMG_SIZE,IMG_SIZE))\n",
    "            image= img_to_array(image)\n",
    "            image = preprocess_input(image)\n",
    "\n",
    "            X.append(image)\n",
    "            Z.append(str(label))\n",
    "        return X,Z\n",
    "IMG_SIZE=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 403/403 [00:02<00:00, 187.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:02<00:00, 218.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 410/410 [00:01<00:00, 218.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [00:02<00:00, 213.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [00:02<00:00, 210.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:00<00:00, 211.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "Z=[]\n",
    "DIR_cardboard='Garbage_classification/cardboard'\n",
    "DIR_glass='Garbage_classification/glass'\n",
    "DIR_metal='Garbage_classification/metal'\n",
    "DIR_paper='Garbage_classification/paper'\n",
    "DIR_plastic='Garbage_classification/plastic'\n",
    "DIR_trash='Garbage_classification/trash'\n",
    "\n",
    "load_data('cardboard',DIR_cardboard)\n",
    "print(len(X))\n",
    "load_data('glass',DIR_glass)\n",
    "print(len(X))\n",
    "load_data('metal',DIR_metal)\n",
    "print(len(X))\n",
    "load_data('paper',DIR_paper)\n",
    "print(len(X))\n",
    "load_data('plastic',DIR_plastic)\n",
    "print(len(X))\n",
    "load_data('trash',DIR_trash)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image dimensions\n",
    "img_rows, img_cols, img_chans = 384, 512, 3\n",
    "input_shape = (img_rows, img_cols, img_chans)\n",
    "batch_size = 8\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    #Loading the VGG model\n",
    "    vgg_conv = VGG16(weights='imagenet', include_top=False,  input_shape=input_shape)\n",
    "    \n",
    "    for i in range(8):\n",
    "        #removing the last layers  \n",
    "        vgg_conv.layers.pop() \n",
    "    \n",
    "    \n",
    "    # Freezing all layers\n",
    "    for layer in vgg_conv.layers[:]:\n",
    "        layer.trainable = False\n",
    "     \n",
    "    # Building Deep learning model\n",
    "    model = models.Sequential()\n",
    "     \n",
    "    # Adding the vgg model\n",
    "    model.add(vgg_conv)\n",
    "     \n",
    "    # Adding new layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(350, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(350, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "     \n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adagrad(lr=1e-5, decay=1e-6), metrics=['accuracy'])\n",
    "    \n",
    "    \"\"\"\n",
    "    files = glob('Model2**')\n",
    "    print(files)\n",
    "    list_models=[]\n",
    "    for  model_ in files:\n",
    "        list_models.append(float(model_[:-5].split('=')[1]))\n",
    "        \n",
    "    index = np.argmin(list_models)\n",
    "    load_model = files[index]\n",
    "    print(load_model)\n",
    "\n",
    "    if load_model is not None:\n",
    "            model.load_weights(load_model)\n",
    "            print(\"weights are loaded\")\n",
    "    else:\n",
    "            print(\"weights are None\")\n",
    "    \"\"\"       \n",
    "    \n",
    "    call =  [                  \n",
    "                                    EarlyStopping(monitor='val_loss',  patience=20, verbose=1,  mode='auto'),\n",
    "            ]\n",
    "    \n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  shuffle=True)\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        # This will do preprocessing and realtime data augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset   \n",
    "        samplewise_center=False,  # set each sample mean to 0   \n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset   \n",
    "        samplewise_std_normalization=False,  # divide each input by its std  \n",
    "        zca_whitening=False,  # apply ZCA whitening     \n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)  <<1    0 => 30\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,  # set range for random shear  <<3<<4  0 => 0.1 => 0.2\n",
    "        zoom_range=0.3,  # set range for random zoom    <<1<<2<<3   0 => 0.1 => 0.2 =>0.3 \n",
    "        channel_shift_range=0.2,  # set range for random channel shifts     <<5<<6   0.=>0.1=>0.2\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"     \n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True,  # randomly flip images    <<1    false => True\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,   \n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "    \n",
    "        print(\"steps_per_epoch (nbr of samples per epoch):\", int(len(x_train)/batch_size))\n",
    "        # Fit the model on the batches generated by datagen.flow().\n",
    "        history = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),steps_per_epoch = 800,\n",
    "                            epochs=50,\n",
    "                            validation_data=(x_test, y_test),\n",
    "                            workers=10, callbacks = call)\n",
    "        \n",
    "        weights = '{}.hdf5'.format('Model3_adagrad_'+'val_acc:'+str(round(history.history['val_acc'][-1],3))+' val_loss='+str(round(history.history['val_loss'][-1],3)))\n",
    "        model.save_weights(weights)\n",
    "        print ('Model saved.')\n",
    "        \n",
    "        score = model.evaluate(x_test, y_test,batch_size=10, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        acc = history.history['acc']\n",
    "        val_acc = history.history['val_acc']\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "\n",
    "        epoch = range(len(acc))\n",
    "\n",
    "        plt.plot(epoch, acc, 'b', label='Training acc')\n",
    "        plt.plot(epoch, val_acc, 'r', label='Validation acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.legend()\n",
    "        plt.figure()\n",
    "\n",
    "        plt.plot(epoch, loss, 'b', label='Training loss')\n",
    "        plt.plot(epoch, val_loss, 'r', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_test):\n",
    "    \n",
    "    image = np.expand_dims((x_test[58] - np.mean(x_test))/ np.std(x_test), axis=0)\n",
    "\n",
    "    plt.imshow(x_test[58])\n",
    "    plt.show()\n",
    "\n",
    "    out = model.predict(x_test[58])\n",
    "    out = np.argmax(out)\n",
    "\n",
    "    if out == 1:\n",
    "            label = 'plastic'\n",
    "    else:\n",
    "            label = 'glass'\n",
    "\n",
    "    return out, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    " \n",
    "\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#model selection\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#preprocess.\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "#dl libraraies\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# specifically for cnn\n",
    "from keras.layers import Dropout, Flatten,Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\n",
    "import cv2                  \n",
    "from tqdm import tqdm\n",
    "import os                   \n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 14s 197ms/step - loss: 1.7406 - accuracy: 0.2098 - val_loss: 1.6965 - val_accuracy: 0.2411\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 13s 199ms/step - loss: 1.6847 - accuracy: 0.2672 - val_loss: 1.6712 - val_accuracy: 0.3182\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 13s 208ms/step - loss: 1.6568 - accuracy: 0.3033 - val_loss: 1.6547 - val_accuracy: 0.2826\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 15s 237ms/step - loss: 1.6326 - accuracy: 0.3315 - val_loss: 1.6434 - val_accuracy: 0.3024\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 12s 187ms/step - loss: 1.6169 - accuracy: 0.3597 - val_loss: 1.6203 - val_accuracy: 0.3360\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 13s 203ms/step - loss: 1.6001 - accuracy: 0.3790 - val_loss: 1.6030 - val_accuracy: 0.3399\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 15s 236ms/step - loss: 1.5842 - accuracy: 0.4003 - val_loss: 1.5835 - val_accuracy: 0.3933\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 15s 238ms/step - loss: 1.5714 - accuracy: 0.4226 - val_loss: 1.5735 - val_accuracy: 0.3972\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 13s 200ms/step - loss: 1.5579 - accuracy: 0.4300 - val_loss: 1.5755 - val_accuracy: 0.3142\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 15s 238ms/step - loss: 1.5493 - accuracy: 0.4394 - val_loss: 1.5630 - val_accuracy: 0.3617\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 15s 232ms/step - loss: 1.5393 - accuracy: 0.4379 - val_loss: 1.5460 - val_accuracy: 0.4269\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 13s 203ms/step - loss: 1.5312 - accuracy: 0.4552 - val_loss: 1.5531 - val_accuracy: 0.3854\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 12s 195ms/step - loss: 1.5226 - accuracy: 0.4532 - val_loss: 1.5327 - val_accuracy: 0.4091\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 12s 190ms/step - loss: 1.5160 - accuracy: 0.4631 - val_loss: 1.5316 - val_accuracy: 0.4387\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 13s 202ms/step - loss: 1.5102 - accuracy: 0.4597 - val_loss: 1.5143 - val_accuracy: 0.4447\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 15s 229ms/step - loss: 1.5013 - accuracy: 0.4730 - val_loss: 1.5109 - val_accuracy: 0.4427\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 15s 227ms/step - loss: 1.4976 - accuracy: 0.4661 - val_loss: 1.5226 - val_accuracy: 0.4387\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 13s 205ms/step - loss: 1.4909 - accuracy: 0.4740 - val_loss: 1.4983 - val_accuracy: 0.4664\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 13s 206ms/step - loss: 1.4847 - accuracy: 0.4725 - val_loss: 1.4989 - val_accuracy: 0.4466\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 16s 251ms/step - loss: 1.4799 - accuracy: 0.4859 - val_loss: 1.4925 - val_accuracy: 0.4526\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 15s 238ms/step - loss: 1.4738 - accuracy: 0.4790 - val_loss: 1.4908 - val_accuracy: 0.4526\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 14s 213ms/step - loss: 1.4692 - accuracy: 0.4859 - val_loss: 1.4816 - val_accuracy: 0.4723\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 13s 201ms/step - loss: 1.4651 - accuracy: 0.4928 - val_loss: 1.4785 - val_accuracy: 0.4427\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 12s 195ms/step - loss: 1.4601 - accuracy: 0.4814 - val_loss: 1.4958 - val_accuracy: 0.4565\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 14s 212ms/step - loss: 1.4561 - accuracy: 0.4904 - val_loss: 1.4750 - val_accuracy: 0.4545\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 13s 197ms/step - loss: 1.4526 - accuracy: 0.4884 - val_loss: 1.4732 - val_accuracy: 0.4526\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 1.4475 - accuracy: 0.4918 - val_loss: 1.4708 - val_accuracy: 0.4644\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 13s 205ms/step - loss: 1.4450 - accuracy: 0.4889 - val_loss: 1.4612 - val_accuracy: 0.4565\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 14s 220ms/step - loss: 1.4416 - accuracy: 0.4938 - val_loss: 1.4631 - val_accuracy: 0.4486\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 14s 215ms/step - loss: 1.4377 - accuracy: 0.4993 - val_loss: 1.4547 - val_accuracy: 0.4783\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 13s 198ms/step - loss: 1.4327 - accuracy: 0.4918 - val_loss: 1.4524 - val_accuracy: 0.4723\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 13s 201ms/step - loss: 1.4306 - accuracy: 0.4958 - val_loss: 1.4573 - val_accuracy: 0.4822\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 13s 197ms/step - loss: 1.4281 - accuracy: 0.5002 - val_loss: 1.4505 - val_accuracy: 0.4743\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 14s 215ms/step - loss: 1.4230 - accuracy: 0.4953 - val_loss: 1.4499 - val_accuracy: 0.4644\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 13s 207ms/step - loss: 1.4209 - accuracy: 0.4943 - val_loss: 1.4441 - val_accuracy: 0.4704\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 14s 211ms/step - loss: 1.4188 - accuracy: 0.4963 - val_loss: 1.4477 - val_accuracy: 0.4704\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 13s 198ms/step - loss: 1.4159 - accuracy: 0.5037 - val_loss: 1.4417 - val_accuracy: 0.4862\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 13s 208ms/step - loss: 1.4131 - accuracy: 0.4998 - val_loss: 1.4428 - val_accuracy: 0.4802\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 14s 218ms/step - loss: 1.4127 - accuracy: 0.4988 - val_loss: 1.4372 - val_accuracy: 0.4763\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 14s 217ms/step - loss: 1.4068 - accuracy: 0.4988 - val_loss: 1.4434 - val_accuracy: 0.4783\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 13s 209ms/step - loss: 1.4062 - accuracy: 0.5032 - val_loss: 1.4357 - val_accuracy: 0.4901\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 14s 216ms/step - loss: 1.4037 - accuracy: 0.5057 - val_loss: 1.4378 - val_accuracy: 0.4723\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 13s 205ms/step - loss: 1.4025 - accuracy: 0.5047 - val_loss: 1.4300 - val_accuracy: 0.4842\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 13s 203ms/step - loss: 1.4000 - accuracy: 0.5072 - val_loss: 1.4323 - val_accuracy: 0.4822\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 13s 195ms/step - loss: 1.3972 - accuracy: 0.5082 - val_loss: 1.4282 - val_accuracy: 0.4862\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 13s 199ms/step - loss: 1.3961 - accuracy: 0.5047 - val_loss: 1.4281 - val_accuracy: 0.4842\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 14s 218ms/step - loss: 1.3934 - accuracy: 0.5052 - val_loss: 1.4305 - val_accuracy: 0.4704\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 13s 205ms/step - loss: 1.3921 - accuracy: 0.5082 - val_loss: 1.4240 - val_accuracy: 0.4901\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 13s 203ms/step - loss: 1.3884 - accuracy: 0.5111 - val_loss: 1.4214 - val_accuracy: 0.4822\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 12s 195ms/step - loss: 1.3872 - accuracy: 0.5146 - val_loss: 1.4192 - val_accuracy: 0.4842\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 13s 209ms/step - loss: 1.3856 - accuracy: 0.5062 - val_loss: 1.4215 - val_accuracy: 0.4704\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 13s 210ms/step - loss: 1.3840 - accuracy: 0.5072 - val_loss: 1.4192 - val_accuracy: 0.4881\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 13s 206ms/step - loss: 1.3824 - accuracy: 0.5151 - val_loss: 1.4152 - val_accuracy: 0.4941\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 14s 220ms/step - loss: 1.3796 - accuracy: 0.5126 - val_loss: 1.4192 - val_accuracy: 0.4842\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 14s 214ms/step - loss: 1.3774 - accuracy: 0.5096 - val_loss: 1.4161 - val_accuracy: 0.4822\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 14s 224ms/step - loss: 1.3758 - accuracy: 0.5111 - val_loss: 1.4136 - val_accuracy: 0.4862\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 13s 197ms/step - loss: 1.3741 - accuracy: 0.5181 - val_loss: 1.4124 - val_accuracy: 0.4921\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 13s 201ms/step - loss: 1.3731 - accuracy: 0.5136 - val_loss: 1.4105 - val_accuracy: 0.4960\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 13s 198ms/step - loss: 1.3714 - accuracy: 0.5111 - val_loss: 1.4162 - val_accuracy: 0.4901\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 13s 196ms/step - loss: 1.3692 - accuracy: 0.5245 - val_loss: 1.4114 - val_accuracy: 0.4822\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 13s 197ms/step - loss: 1.3683 - accuracy: 0.5121 - val_loss: 1.4090 - val_accuracy: 0.4783\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 13s 196ms/step - loss: 1.3659 - accuracy: 0.5166 - val_loss: 1.4126 - val_accuracy: 0.4644\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 12s 195ms/step - loss: 1.3651 - accuracy: 0.5186 - val_loss: 1.4069 - val_accuracy: 0.4862\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 1.3635 - accuracy: 0.5166 - val_loss: 1.4112 - val_accuracy: 0.4644\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 13s 196ms/step - loss: 1.3617 - accuracy: 0.5141 - val_loss: 1.4048 - val_accuracy: 0.4842\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 13s 203ms/step - loss: 1.3608 - accuracy: 0.5146 - val_loss: 1.4017 - val_accuracy: 0.4941\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 12s 195ms/step - loss: 1.3588 - accuracy: 0.5171 - val_loss: 1.4008 - val_accuracy: 0.4960\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 1.3569 - accuracy: 0.5200 - val_loss: 1.4017 - val_accuracy: 0.4822\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 1.3544 - accuracy: 0.5146 - val_loss: 1.4019 - val_accuracy: 0.4921\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 13s 200ms/step - loss: 1.3530 - accuracy: 0.5205 - val_loss: 1.3986 - val_accuracy: 0.4842\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 13s 207ms/step - loss: 1.3520 - accuracy: 0.5265 - val_loss: 1.4018 - val_accuracy: 0.4842\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 14s 211ms/step - loss: 1.3512 - accuracy: 0.5205 - val_loss: 1.4029 - val_accuracy: 0.4763\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 13s 200ms/step - loss: 1.3498 - accuracy: 0.5200 - val_loss: 1.4007 - val_accuracy: 0.4881\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 13s 200ms/step - loss: 1.3487 - accuracy: 0.5200 - val_loss: 1.3962 - val_accuracy: 0.4862\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 13s 203ms/step - loss: 1.3464 - accuracy: 0.5250 - val_loss: 1.3952 - val_accuracy: 0.4862\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 13s 198ms/step - loss: 1.3441 - accuracy: 0.5235 - val_loss: 1.3964 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 13s 199ms/step - loss: 1.3425 - accuracy: 0.5220 - val_loss: 1.3993 - val_accuracy: 0.4842\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 13s 202ms/step - loss: 1.3412 - accuracy: 0.5191 - val_loss: 1.3966 - val_accuracy: 0.4822\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 14s 216ms/step - loss: 1.3414 - accuracy: 0.5265 - val_loss: 1.3931 - val_accuracy: 0.4941\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 13s 203ms/step - loss: 1.3381 - accuracy: 0.5260 - val_loss: 1.3912 - val_accuracy: 0.4941\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 13s 203ms/step - loss: 1.3371 - accuracy: 0.5240 - val_loss: 1.3915 - val_accuracy: 0.4802\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 13s 203ms/step - loss: 1.3356 - accuracy: 0.5275 - val_loss: 1.3904 - val_accuracy: 0.4842\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 13s 202ms/step - loss: 1.3341 - accuracy: 0.5220 - val_loss: 1.3943 - val_accuracy: 0.4743\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 13s 201ms/step - loss: 1.3331 - accuracy: 0.5250 - val_loss: 1.3881 - val_accuracy: 0.4822\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 14s 226ms/step - loss: 1.3319 - accuracy: 0.5280 - val_loss: 1.3880 - val_accuracy: 0.4862\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 16s 257ms/step - loss: 1.3299 - accuracy: 0.5235 - val_loss: 1.3893 - val_accuracy: 0.4862\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 16s 243ms/step - loss: 1.3303 - accuracy: 0.5210 - val_loss: 1.3861 - val_accuracy: 0.4802\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 15s 239ms/step - loss: 1.3270 - accuracy: 0.5289 - val_loss: 1.3854 - val_accuracy: 0.4881\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 16s 243ms/step - loss: 1.3259 - accuracy: 0.5255 - val_loss: 1.3886 - val_accuracy: 0.4941\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 18s 284ms/step - loss: 1.3242 - accuracy: 0.5250 - val_loss: 1.3930 - val_accuracy: 0.4763\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 16s 244ms/step - loss: 1.3241 - accuracy: 0.5280 - val_loss: 1.3859 - val_accuracy: 0.4941\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 16s 245ms/step - loss: 1.3221 - accuracy: 0.5299 - val_loss: 1.3846 - val_accuracy: 0.4763\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 16s 244ms/step - loss: 1.3216 - accuracy: 0.5250 - val_loss: 1.3843 - val_accuracy: 0.4842\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 16s 248ms/step - loss: 1.3200 - accuracy: 0.5280 - val_loss: 1.3821 - val_accuracy: 0.4802\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 19s 294ms/step - loss: 1.3182 - accuracy: 0.5294 - val_loss: 1.3830 - val_accuracy: 0.4941\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 18s 282ms/step - loss: 1.3169 - accuracy: 0.5309 - val_loss: 1.3812 - val_accuracy: 0.4862\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 16s 243ms/step - loss: 1.3156 - accuracy: 0.5270 - val_loss: 1.3821 - val_accuracy: 0.4980\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 15s 242ms/step - loss: 1.3150 - accuracy: 0.5285 - val_loss: 1.3822 - val_accuracy: 0.4743\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 16s 244ms/step - loss: 1.3132 - accuracy: 0.5294 - val_loss: 1.3798 - val_accuracy: 0.4881\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 15s 237ms/step - loss: 1.3117 - accuracy: 0.5339 - val_loss: 1.3796 - val_accuracy: 0.4842\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "\n",
    "# Define the path to your image dataset\n",
    "dataset_path = 'Garbage_classification'\n",
    "\n",
    "# Define the desired image size\n",
    "target_size = (256, 256)\n",
    "\n",
    "# Load and preprocess the images\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate over the images in the dataset\n",
    "for label in os.listdir(dataset_path):\n",
    "    label_path = os.path.join(dataset_path, label)\n",
    "    if os.path.isdir(label_path):\n",
    "        for image_file in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, target_size)\n",
    "            all_images.append(image)\n",
    "            all_labels.append(label)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "all_images = np.array(all_images)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_images, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n",
    ")\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Convert labels to integer type\n",
    "label_mapping = {label: idx for idx, label in enumerate(np.unique(all_labels))}\n",
    "y_train = np.array([label_mapping[label] for label in y_train])\n",
    "y_test = np.array([label_mapping[label] for label in y_test])\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = np.eye(len(label_mapping))[y_train]\n",
    "y_test = np.eye(len(label_mapping))[y_test]\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(target_size[0], target_size[1], 3)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dense(len(label_mapping), activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=legacy.Adagrad(learning_rate=1e-5, decay=1e-6),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the path to your image dataset directory\n",
    "dataset_dir = 'Garbage_classification'\n",
    "\n",
    "# Define the desired image size\n",
    "target_size = (256, 256)\n",
    "\n",
    "# Load and preprocess the images\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate over the images in the dataset\n",
    "for label in os.listdir(dataset_dir):\n",
    "    label_path = os.path.join(dataset_dir, label)\n",
    "    if os.path.isdir(label_path):\n",
    "        for image_file in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, target_size)\n",
    "            all_images.append(image)\n",
    "            all_labels.append(label)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "all_images_array = np.array(all_images)\n",
    "all_labels_array = np.array(all_labels)\n",
    "\n",
    "# Map string labels to integer values\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels_encoded = label_encoder.fit_transform(all_labels_array)\n",
    "\n",
    "# Save the label encoder for future reference\n",
    "np.save('label_encoder.npy', label_encoder.classes_)\n",
    "\n",
    "# Save the numpy arrays as files\n",
    "np.save('all_images_array.npy', all_images_array)\n",
    "np.save('all_labels.npy', all_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1768, 256, 256, 3)\n",
      "1768 train samples\n",
      "759 test samples\n",
      "Epoch 1/10\n",
      "56/56 [==============================] - 21s 351ms/step - loss: 37.0083 - accuracy: 0.2178 - val_loss: 10.9076 - val_accuracy: 0.2082\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 19s 343ms/step - loss: 7.5413 - accuracy: 0.2698 - val_loss: 3.7419 - val_accuracy: 0.2899\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 19s 336ms/step - loss: 3.4681 - accuracy: 0.3269 - val_loss: 5.0921 - val_accuracy: 0.2464\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 19s 336ms/step - loss: 3.6869 - accuracy: 0.3015 - val_loss: 2.8034 - val_accuracy: 0.2398\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 19s 332ms/step - loss: 2.0881 - accuracy: 0.3665 - val_loss: 1.8531 - val_accuracy: 0.4387\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 19s 339ms/step - loss: 2.1015 - accuracy: 0.3445 - val_loss: 3.2768 - val_accuracy: 0.1884\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 19s 332ms/step - loss: 1.9348 - accuracy: 0.3863 - val_loss: 1.9403 - val_accuracy: 0.2991\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 18s 329ms/step - loss: 2.0780 - accuracy: 0.3529 - val_loss: 2.2128 - val_accuracy: 0.3755\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 18s 329ms/step - loss: 1.8905 - accuracy: 0.3552 - val_loss: 2.3320 - val_accuracy: 0.2846\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 18s 328ms/step - loss: 1.8232 - accuracy: 0.3710 - val_loss: 1.7878 - val_accuracy: 0.2859\n",
      "24/24 [==============================] - 1s 21ms/step\n",
      "The predictions of the test set are: [[4.50083092e-02 3.66980344e-01 2.21607119e-01 6.56540394e-02\n",
      "  2.31092528e-01 6.96576014e-02]\n",
      " [6.43486669e-03 5.92182219e-01 1.24495178e-01 2.61298735e-02\n",
      "  2.50657737e-01 1.00156336e-04]\n",
      " [4.90745949e-03 4.83043008e-02 7.01037765e-01 5.42719811e-02\n",
      "  1.90693349e-01 7.85150798e-04]\n",
      " ...\n",
      " [1.95864234e-02 8.32041651e-02 5.39829016e-01 1.65403709e-01\n",
      "  1.90936342e-01 1.04029803e-03]\n",
      " [9.15093627e-03 1.98192805e-01 5.16510487e-01 4.00925763e-02\n",
      "  2.35860854e-01 1.92341889e-04]\n",
      " [3.80101614e-02 4.31730837e-01 1.88954905e-01 5.93920127e-02\n",
      "  2.64262348e-01 1.76497195e-02]]\n",
      "The predicted labels are: [1 1 2 2 2 2 2 2 2 0 2 2 4 0 1 2 2 2 4 1 2 2 1 1 2 1 0 2 5 2 2 4 2 2 1 0 2\n",
      " 2 2 1 4 1 1 1 2 2 2 1 2 1 2 1 0 1 2 2 2 1 4 1 1 4 0 2 1 2 2 0 1 4 2 2 2 0\n",
      " 2 1 2 2 0 2 2 1 2 2 2 2 5 2 1 1 2 2 2 1 2 1 2 0 1 2 2 4 1 2 2 2 3 2 2 0 2\n",
      " 2 2 2 2 1 1 2 2 2 4 2 4 1 0 2 2 2 2 1 1 0 1 1 2 2 2 2 2 1 2 0 0 5 4 2 2 2\n",
      " 1 2 2 1 2 4 2 2 2 1 1 2 2 1 2 2 2 2 2 2 1 2 1 2 2 1 2 1 2 2 1 1 2 2 2 2 2\n",
      " 1 2 2 4 2 2 2 2 1 4 2 0 2 0 2 1 1 2 0 1 1 0 2 0 2 1 0 2 2 1 4 2 2 2 1 2 2\n",
      " 1 2 2 2 2 2 2 2 2 1 1 2 2 2 1 2 2 2 2 2 1 2 1 1 2 1 4 2 2 1 5 2 2 0 1 0 1\n",
      " 1 0 0 1 2 1 2 1 1 1 2 2 2 1 2 4 1 2 2 2 1 2 2 1 0 1 2 1 1 2 2 2 4 2 2 1 5\n",
      " 2 2 1 1 0 1 2 4 0 0 1 0 2 1 2 0 2 2 1 2 5 2 1 2 4 2 0 1 2 0 2 2 1 2 0 2 1\n",
      " 2 2 1 2 0 0 1 2 1 1 1 2 0 2 2 4 2 0 1 5 1 2 2 2 2 2 2 2 2 2 5 0 1 2 1 2 1\n",
      " 2 0 1 1 4 2 4 2 2 2 1 0 2 2 1 2 4 0 1 2 1 2 3 2 0 1 1 2 0 5 2 2 0 1 1 2 1\n",
      " 2 2 1 0 1 2 2 1 4 2 2 1 3 0 2 2 1 5 1 2 2 2 1 1 0 2 2 2 2 1 1 1 2 1 1 1 4\n",
      " 2 2 1 1 2 2 2 1 2 2 2 2 2 2 1 0 2 4 2 2 2 2 2 2 2 4 2 1 2 1 5 2 4 2 2 2 2\n",
      " 2 5 0 5 2 1 2 2 0 2 2 1 1 2 1 2 1 4 2 2 1 1 0 1 2 2 0 2 4 2 4 1 2 1 2 2 2\n",
      " 1 2 2 1 2 2 1 2 2 1 2 2 0 2 2 1 2 1 2 2 1 1 1 2 1 0 2 2 1 4 2 0 4 0 2 2 1\n",
      " 0 1 2 2 2 1 2 4 2 2 4 2 2 2 1 0 5 2 2 1 2 2 2 2 1 2 0 1 4 2 2 2 0 1 2 5 2\n",
      " 2 2 4 2 2 1 2 2 1 2 2 2 1 1 2 2 2 1 2 2 2 2 2 4 0 2 1 2 2 1 0 2 2 2 2 2 2\n",
      " 0 2 1 2 2 2 2 2 1 2 2 0 0 2 1 1 2 4 0 0 2 2 2 2 1 2 2 5 3 1 4 2 1 0 2 1 5\n",
      " 1 0 2 2 1 2 2 2 2 1 1 2 0 2 1 1 2 1 2 1 2 0 1 0 1 1 2 2 5 1 2 1 0 2 2 2 2\n",
      " 3 2 2 4 2 2 1 2 2 1 2 2 0 2 2 2 2 1 2 1 1 4 1 2 2 2 1 0 2 2 1 2 2 0 4 2 2\n",
      " 2 2 2 2 2 2 0 1 0 2 2 2 0 2 2 2 2 2 1]\n",
      "24/24 [==============================] - 1s 20ms/step - loss: 1.3092 - accuracy: 0.5494\n",
      "Test accuracy: 0.5494071245193481\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def train(x_train, x_test, y_train, y_test):\n",
    "    # Define and train your model here\n",
    "    # Example placeholder code\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(256, 256, 3)))  # Flatten the input shape\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    \n",
    "    model.save('your_model.h5')  # Save the trained model\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test(x_test):\n",
    "    # Define your test function here\n",
    "    # Example placeholder code\n",
    "    model = keras.models.load_model('your_model.h5')  # Load your trained model\n",
    "    predictions = model.predict(x_test)\n",
    "    # Perform any necessary post-processing on predictions\n",
    "    labels = np.argmax(predictions, axis=1)\n",
    "    return predictions, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load all images\n",
    "    all_images_array = np.load('all_images_array.npy')\n",
    "\n",
    "    # Load the class labels\n",
    "    all_labels = np.load('all_labels.npy')\n",
    "\n",
    "    # Load the label encoder for future use\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_labels_encoded = label_encoder.fit_transform(all_labels)\n",
    "\n",
    "    # Split the dataset into train and test sets, with a split ratio of 70:30\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        all_images_array, all_labels_encoded, test_size=0.30, shuffle=True, random_state=78\n",
    "    )\n",
    "\n",
    "    # Data normalization to convert features to the same scale\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # Convert class vectors to one-hot encoding\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    train(x_train, x_test, y_train, y_test)\n",
    "\n",
    "    predictions, labels = test(x_test)\n",
    "\n",
    "    print('The predictions of the test set are:', predictions)\n",
    "    print('The predicted labels are:', labels)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    _, accuracy = model.evaluate(x_test, y_test)\n",
    "    print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 196608)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                12582976  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,587,526\n",
      "Trainable params: 12,587,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('your_model.h5')  # Load your trained model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56/56 [==============================] - 21s 349ms/step - loss: 2.0522 - accuracy: 0.3439 - val_loss: 2.3653 - val_accuracy: 0.3136\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 19s 340ms/step - loss: 1.6518 - accuracy: 0.4005 - val_loss: 1.7240 - val_accuracy: 0.3518\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 20s 349ms/step - loss: 1.5690 - accuracy: 0.4180 - val_loss: 1.5494 - val_accuracy: 0.4585\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 19s 334ms/step - loss: 1.3488 - accuracy: 0.4683 - val_loss: 1.8027 - val_accuracy: 0.3307\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 19s 333ms/step - loss: 1.3692 - accuracy: 0.4593 - val_loss: 1.6339 - val_accuracy: 0.3202\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 20s 352ms/step - loss: 1.4133 - accuracy: 0.4604 - val_loss: 1.4933 - val_accuracy: 0.4506\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 19s 347ms/step - loss: 1.4161 - accuracy: 0.4553 - val_loss: 2.1015 - val_accuracy: 0.2253\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 19s 340ms/step - loss: 1.4212 - accuracy: 0.4666 - val_loss: 1.6861 - val_accuracy: 0.4374\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 20s 355ms/step - loss: 1.3714 - accuracy: 0.4531 - val_loss: 1.7373 - val_accuracy: 0.3636\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 20s 353ms/step - loss: 1.3419 - accuracy: 0.4791 - val_loss: 2.1945 - val_accuracy: 0.2253\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # Define the number of training epochs\n",
    "batch_size = 32  # Define the batch size\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# Retrieve validation accuracy\n",
    "validation_accuracy = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 27ms/step\n",
      "24/24 [==============================] - 1s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded or trained a model named 'model'\n",
    "# and have a test data set named 'x_test'\n",
    "\n",
    "# Get prediction probabilities for each class\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# The 'predictions' variable will be a 2D array where each row represents a sample in 'x_test'\n",
    "# and each column represents the prediction probability for a specific class\n",
    "\n",
    "# For example, to get the confidence score for the first sample in 'x_test' for class 0:\n",
    "confidence_score = predictions[0][0]\n",
    "# Assuming you have loaded or trained a model named 'model'\n",
    "# and have a test data set named 'x_test'\n",
    "\n",
    "# Assuming you have loaded or trained a model named 'model'\n",
    "# and have a test data set named 'x_test'\n",
    "\n",
    "# Get predicted probabilities for each class\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Get predicted class labels using argmax\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "\n",
    "# The 'predicted_classes' variable will be a 1D array where each element represents the predicted class label for a specific sample in 'x_test'\n",
    "\n",
    "# For example, to get the predicted class label for the first sample in 'x_test':\n",
    "class_label = predicted_classes[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
